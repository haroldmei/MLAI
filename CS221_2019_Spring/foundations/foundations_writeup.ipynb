{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS221, Spring 2019, PS1 Foundations\n",
    "Haiyuan Mei (hmei0411@stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Optimization and probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a\n",
    "Since $w_1, \\dots, w_n$ are strictly positive, $f(\\theta)$ is a convex function which takes minimum value when $f'(\\theta)=0$. Take the derivative of $f(\\theta)$:  \n",
    "$$\\begin{eqnarray*}\n",
    "f'(\\theta) &=& \\sum_{i=1}^n w_i (\\theta - x_i) \\\\\n",
    "&=& \\sum_{i=1}^n w_i \\theta - \\sum_{i=1}^n w_i x_i \n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Set the above to be 0 and solve the equation:\n",
    "$$\n",
    "\\theta = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}\n",
    "$$\n",
    "\n",
    "If some of the $w_i$ are negative, but $\\sum_{i=1}^n w_i$ is positive, the result is still the same.  \n",
    "If some of the $w_i$ are negative, and $\\sum_{i=1}^n w_i$ is negative too, $f(\\theta)$ will become concave and has no minumum.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b\n",
    "Answer should be: $f(\\mathbf x) \\ge g(\\mathbf x)$  \n",
    "Proof:\n",
    "For $g(\\mathbf x) = \\max_{s \\in \\{1,-1\\}} \\sum_{i=1}^d s x_i$, depending on the sign of $\\sum_{i=1}^d s x_i$, $g(\\mathbf x)$ takes the maximum on either $s = 1$ or $s = -1$. Suppose it takes the maximum when $s = 1$, we have:  \n",
    "$$\\begin{eqnarray*}\n",
    "g(\\mathbf x) &=& \\max_{s \\in \\{1,-1\\}} \\sum_{i=1}^d s x_i \\\\\n",
    "&=& \\sum_{i=1}^d x_i \\\\\n",
    "&\\le& \\sum_{i=1}^d \\max_{s \\in \\{1,-1\\}} s x_i \\\\\n",
    "&=& f(\\mathbf x)\n",
    "\\end{eqnarray*}$$  \n",
    "When the maximum is with $s = -1$, simple change the above equation to be:  \n",
    "$$\\begin{eqnarray*}\n",
    "g(\\mathbf x) &=& \\max_{s \\in \\{1,-1\\}} \\sum_{i=1}^d s x_i \\\\\n",
    "&=& \\sum_{i=1}^d -x_i \\\\\n",
    "&\\le& \\sum_{i=1}^d \\max_{s \\in \\{1,-1\\}} s x_i \\\\\n",
    "&=& f(\\mathbf x)\n",
    "\\end{eqnarray*}$$  \n",
    "Question proved.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.c\n",
    "Solution 1: Suppose the expected number of points is x, the following equation is true:\n",
    "$$\n",
    "x = \\frac{5}{6} x + \\frac{1}{6} (b-a) \n",
    "$$\n",
    "The above equation says that the expected number of points x is equal to half of x which comes from 3,4 or 5, and $\\frac{1}{6} (b - a)$ which is from 2 or 6; The probability of taking each of the value is $\\frac{1}{6}$. The solution of above gives $x = b - a $.  \n",
    "\n",
    "Solution 2: \n",
    "At each time the expected number of points should be $\\frac{1}{6} (b - a)$, and the probability of moving to next time is $\\frac{5}{6}$. So the expected number of points can be written as:  \n",
    "$$\n",
    "x = \\sum_{i=0}^\\infty \\frac{5}{6}^i \\frac{b-a}{6} = b - a\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d\n",
    "If stop at nth turn, the expected point is: $E_n = \\sum_{i=1}^{n-1}\\frac{3}{5}^i 3 + \\frac{3}{5}^n 15$;  \n",
    "when n = 1, $E_1 = 9$;  \n",
    "when n = 2, $E_2 = 7.2$;  \n",
    "when n = 3, $E_3 = 6.12$;  \n",
    "...  \n",
    "when n = $\\infty$, $E_{\\infty} = 4.5$;  \n",
    "Which means the earlier we stop the game the higher the expected points. So the strategy should be stop at begining.\n",
    "\n",
    "If the probability of rolling an even number is 0, then the strategy should be never stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.e\n",
    "In order to maximize the $L(p)$, consider the derivative w.r.t. $\\log L(p)$:  \n",
    "$$\n",
    "\\log L(p) = 4 \\log p + 3 \\log (1 - p)\n",
    "$$\n",
    "take the derivative with respect to $p$ and set it to 0 we have:  \n",
    "$$\n",
    "\\frac{4}{p} = \\frac{3}{1-p}\n",
    "$$\n",
    "the solution should be $p = \\frac{4}{7}$.  \n",
    "The intuitive interpretation of value p is that the expected probability of getting a head when flipping this coin is 4/7 if the result array is {H,H,T,H,T,T,H}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.f\n",
    "The original function can be written with as:\n",
    "$$\n",
    "f(w) = \\sum_{i=0}^n \\sum_{j=0}^n ((a_i^T - b_j^T)w )^2 + \\lambda w^T w\n",
    "$$\n",
    "\n",
    "Apply $\\nabla tr AB = B^T$, it's easy to see that $\\nabla w^T w = 2w$;  \n",
    "also consider $(a_i^T - b_j^T)w  = tr(a_i^T - b_j^T)w = tr (w(a_i^T - b_j^T))$, it's gradient is $(a_i - b_j)$;   \n",
    "so that $\\nabla ((a_i^T - b_j^T)w )^2 = 2 (a_i^T - b_j^T)w \\nabla tr((a_i^T - b_j^T)w) = 2 (a_i^T - b_j^T)w (a_i - b_j)$;  \n",
    "put things together we have:  \n",
    "$$\n",
    "\\nabla f(w) = \\sum_{i=0}^n \\sum_{j=0}^n 2 (a_i^T - b_j^T) w (a_i - b_j) + 2\\lambda w\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.a\n",
    "Suppose each component resides in an rectangle starting from $(x_1,y_1)$ to $(x_2,y_2)$. Since $x$ and $y$ are ranging from 1 to n, the starting point has $n^2$ possibilities, the ending point also has $n^2$ possibilities, so each component has $n^4$ possibilities. There are 5 components, so there are $O(n^{20})$ possibile faces.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. b\n",
    "The problem can be solved by dynamic programming.  \n",
    "Suppose the minimum cost of reaching point $(x,y)$ is denoted as $f(x,y)$ where both $x,y \\in [1,n]$; The following are true:  \n",
    "$$\\begin{eqnarray*}\n",
    "f(x,y) &=& \\min (f(x-1, y), f(x, y-1)) + c(x,y) \\\\\n",
    "f(1,y) &=& f(1, y-1) + c(1,y)  \\\\\n",
    "f(x,1) &=& f(x-1, 1) + c(x,1)  \\\\\n",
    "f(1,1) &=& c(1,1)  \\\\\n",
    "\\end{eqnarray*}$$\n",
    "Using dynamic programming, we need to compute for each grid the minimum cost, which is just $O(n^2)$ run time complexity.  \n",
    "Apart from that, we also need $O(n^2)$ storage complexity for all the intermediate costs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c\n",
    "It is obvious to see that the problem can be written as: $ f(n) = f(n-1) + (n-1) $  \n",
    "This gives the following:\n",
    "$$\\begin{eqnarray*}\n",
    "f(2) - f(1) = 1 \\\\\n",
    "f(3) - f(2) = 2 \\\\\n",
    "f(4) - f(3) = 3 \\\\\n",
    "... \\\\\n",
    "f(n) - f(n-1) = (n-1)\n",
    "\\end{eqnarray*}$$  \n",
    "\n",
    "Sum the above we have: $f(n) - f(1) = 1+2+...+(n-1)$, so:  \n",
    "$$\n",
    "f(n) = \\frac{n(n-1)}{2} + 1\n",
    "$$\n",
    "There are $\\frac{n(n-1)}{2} + 1$ ways to reach the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d\n",
    "Rewrite $f(w)$ and use the fact that $tr ABC = tr CAB = tr BCA $, we have:\n",
    "$$\\begin{eqnarray*}\n",
    "f(w) &=& \\sum_{i=0}^n \\sum_{j=0}^n (a_i^T - b_j^T)w w^T (a_i - b_j) + \\lambda w^T w \\\\\n",
    " &=& \\sum_{i=0}^n \\sum_{j=0}^n w^T (a_i - b_j)(a_i^T - b_j^T)w  + \\lambda w^T w \\\\\n",
    " &=& w^T \\left (\\sum_{i=0}^n \\sum_{j=0}^n(a_i - b_j)(a_i^T - b_j^T) \\right ) w  + \\lambda w^T w \\\\\n",
    "\\end{eqnarray*}$$  \n",
    "\n",
    "We can preprocess the double summation part denoted by $M$, which is just an $n \\times n$ matrix:\n",
    "$$\\begin{eqnarray*}\n",
    "M &=& \\sum_{i=0}^n \\sum_{j=0}^n(a_i - b_j)(a_i^T - b_j^T) \\\\\n",
    "&=& \\sum_{i=0}^n \\sum_{j=0}^n (a_i a_i^T + b_j b_j^T - a_i b_j^T - b_j a_i^T) \\\\\n",
    "&=& n \\sum_{i=0}^n a_i a_i^T + n \\sum_{j=0}b_j b_j^T - A B^T - (A B^T)^T\n",
    "\\end{eqnarray*}$$  \n",
    "* The part $\\sum_{i=0}^n a_i a_i^T$ and $\\sum_{i=0}^n a_i a_i^T$ both takes $d^2$ steps(multiplication) to compute.   \n",
    "* For $A B^T$ part ($A = [a_1,\\dots, a_n], B = [b_1,\\dots, b_n]$), they both are $n \\times d$ matrix, so $A B^T$ ends up with a $d \\times d$ matrix, each element is a sum of n values comes from n multiplications. So the total steps of calculation $A B^T$ is $nd^2$.  \n",
    "* Summarize the above two we can conclude that the preprocess takes complexity of $O(nd^2)$.\n",
    "* After preprocessing, for any given $w$, $w^T M w$ takes $d^2$ multiplications, and $\\lambda w w^T$ takes $d$ multiplications, which concludes that $f(w)$ has complexity of $O(d^2)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
