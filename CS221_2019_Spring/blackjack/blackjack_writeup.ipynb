{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS221, Spring 2019, PS2 Reconstruct\n",
    "Haiyuan Mei (hmei0411@stanford.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Value Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Give the value of $V_{opt}(s)$ for each state s afte 0,1,2 iterations\n",
    "The following table shows values of each state after 0,1,2 iterations. Each row is an iteration, each column denotes a state. Suppose we apply the synchronized update, meaning iteration i updates are based on iteration i-1 results.   \n",
    "\n",
    "First initialize all values to be 0 in iteration 0;\n",
    "\n",
    "According to the updating rule: $V^{t}(s) = \\max_{a \\in A} \\sum_{s'}T(s,a,s')\\left (R(s,a,s') + \\gamma V^{t-1}(s') \\right )$  \n",
    "In iteration 1:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 0 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 0 ) \\right ) = 15 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 0 ) + 0.2 * (-5 + 0 ), 0.3 * (-5 + 0 ) + 0.7 * ( -5 + 0 ) \\right ) = -5\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 0 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 0 ) + 0.7 * ( 100 + 0 ) \\right ) = 68.5\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "In iteration 2:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + -5 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + -5 ) \\right ) = 14 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 15 ) + 0.2 * (-5 + 68.5 ), 0.3 * (-5 + 15 ) + 0.7 * ( -5 + 68.5 ) \\right ) = 47.45\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + -5 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + -5 ) + 0.7 * ( 100 + 0 ) \\right ) = 67\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Put the results in a table, the '-1/+1' in the brackets are actions taken by the states:\n",
    "\n",
    "| state   |   -2   |    -1   |    0    |    1    |    2    |\n",
    "|---------|--------|---------|---------|---------|---------|\n",
    "| itr = 0 |    0   |    0    |    0    |    0    |    0    |\n",
    "| itr = 1 |    0   |  15(-1) | -5(tie) | 68.5(+1)|    0    |\n",
    "| itr = 2 |    0   |  14(-1) |47.45(+1)| 67(+1)  |    0    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. What's the resulting optimal policy $\\pi_{opt}$?\n",
    "Run the iteration a couple of more times.\n",
    "\n",
    "In iteration 3:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 47.45 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 47.45 ) \\right ) = 35.7 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 14 ) + 0.2 * (-5 + 67 ), 0.3 * (-5 + 14 ) + 0.7 * ( -5 + 67 ) \\right ) = 46.1\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 47.45 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 47.45 ) + 0.7 * ( 100 + 0 ) \\right ) = 82.735\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "In iteration 4:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 46.1 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 46.1 ) \\right ) = 34.77 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 35.7 ) + 0.2 * (-5 + 82.735 ), 0.3 * (-5 + 35.7 ) + 0.7 * ( -5 + 82.735 ) \\right ) = 63.62\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 46.1 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 46.1 ) + 0.7 * ( 100 + 0 ) \\right ) = 82.33\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "In iteration 5:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 63.62 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 63.62 ) \\right ) = 47 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 34.77 ) + 0.2 * (-5 + 82.335 ), 0.3 * (-5 + 34.77 ) + 0.7 * ( -5 + 82.33 ) \\right ) = 63\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 63.6 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 63.6 ) + 0.7 * ( 100 + 0 ) \\right ) = 87.6\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "In iteration 6:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 63 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 63 ) \\right ) = 46.6 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 47 ) + 0.2 * (-5 + 87.6 ), 0.3 * (-5 + 47 ) + 0.7 * ( -5 + 87.6 ) \\right ) = 70.42\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 63 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 63 ) + 0.7 * ( 100 + 0 ) \\right ) = 87.4\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "In iteration 7:\n",
    "$$\\begin{eqnarray*}\n",
    "V(-2) &=& V(2) = 0 \\\\\n",
    "V(-1) &=& \\max \\left( 0.8 * (20 + 0 ) + 0.2 * (-5 + 70.42 ), 0.3 * (20 + 0 ) + 0.7 * ( -5 + 70.42 ) \\right ) = 51.8 \\\\\n",
    "V(0) &=& \\max \\left( 0.8 * (-5 + 46.6 ) + 0.2 * (-5 + 87.4 ), 0.3 * (-5 + 46.6 ) + 0.7 * ( -5 + 87.4) \\right ) = 70\\\\\n",
    "V(1) &=& \\max \\left( 0.8 * (-5 + 70.42 ) + 0.2 * (100 + 0 ), 0.3 * (-5 + 70.42) + 0.7 * ( 100 + 0 ) \\right ) = 89.6\n",
    "\\end{eqnarray*}$$\n",
    "\n",
    "Put these in a table, together with the actions taken by each state:\n",
    "\n",
    "\n",
    "| state   |   -2   |    -1   |    0    |    1    |    2    |\n",
    "|---------|--------|---------|---------|---------|---------|\n",
    "| itr = 3 |    0   | 35.7(+1)|46.1(+1) |82.73(+1)|    0    |\n",
    "| itr = 4 |    0   |34.77(+1)|63.62(+1)|82.33(+1)|    0    |\n",
    "| itr = 5 |    0   | 47(+1)  | 63(+1)  |87.6(+1) |    0    |\n",
    "| itr = 6 |    0   | 46.6(+1)|70.42(+1)|87.4(+1) |    0    |\n",
    "| itr = 7 |    0   |51.8(+1) | 70(+1)  |89.6(+1) |    0    |\n",
    "\n",
    "From the above table we can see that all non-terminal states will finally make (+1) as the optimal policy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Transforming MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Does the optimal value always get worse when add noise to the transition?\n",
    "False, see conter-example implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Compute $V_{opt}$ with only a single pass for acyclic MDP.\n",
    "Use a vector $v$ to denote the values for all states, then the $n$ values state space can be denoted as an $n$-dimensional vector. The state transition update can be denoted as:\n",
    "$$\n",
    "v^{t} \\leftarrow M v^{t-1}\n",
    "$$\n",
    "Where $M$ is the transition matrix. (Explain how the transition matrix is composed.)  \n",
    "\n",
    "The goal of convergence is to find a $v$ s.t.\n",
    "$$\n",
    "v = M v\n",
    "$$\n",
    "Now apply linear algebra knowledge, the above equation says that, vector $v$ is just an eigenvector with eigenvalue 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Leverage the MDP solver with $\\gamma=1$ to solve the original MDP with $\\gamma\\lt 1$\n",
    "\n",
    "* Hint, does it relate to an end state?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
